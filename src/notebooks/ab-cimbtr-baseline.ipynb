{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:25.477790Z","iopub.execute_input":"2025-01-18T13:05:25.478357Z","iopub.status.idle":"2025-01-18T13:05:25.672446Z","shell.execute_reply.started":"2025-01-18T13:05:25.478326Z","shell.execute_reply":"2025-01-18T13:05:25.671564Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"\"\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Preparation Steps of Data for Performing Baseline calculation","metadata":{}},{"cell_type":"code","source":"# load the data\nraw_df_train = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\nraw_df_test = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:27.350459Z","iopub.execute_input":"2025-01-18T13:05:27.350771Z","iopub.status.idle":"2025-01-18T13:05:27.689160Z","shell.execute_reply.started":"2025-01-18T13:05:27.350748Z","shell.execute_reply":"2025-01-18T13:05:27.688246Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# differentiate the categorical and numerical cols\ndef identify_numerical_catergorical_columns(df):\n    \"\"\"\n    Identify the Numerical and the Categorical Columns in the dataframe\n    \"\"\"\n    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n    categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n\n    return numerical_cols, categorical_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:30.369473Z","iopub.execute_input":"2025-01-18T13:05:30.369876Z","iopub.status.idle":"2025-01-18T13:05:30.374788Z","shell.execute_reply.started":"2025-01-18T13:05:30.369845Z","shell.execute_reply":"2025-01-18T13:05:30.373977Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# create data pre procesing pipeline\ndef get_data_transformer_object(numerical_cols, categorical_cols):\n    num_pipeline = Pipeline(\n                steps=[\n                    ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n                    \n                ]\n            )\n\n    cat_pipeline = Pipeline(\n                steps = [\n                    ('imputer', SimpleImputer(strategy='constant', fill_value='other')),\n                    (\"label_encoder\", OrdinalEncoder())\n                ]\n            )\n\n    preprocessor = ColumnTransformer(\n                [\n                    (\"num\", num_pipeline, numerical_cols),\n                    (\"cat\", cat_pipeline, categorical_cols)\n                ]\n            )\n\n    return preprocessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:32.040971Z","iopub.execute_input":"2025-01-18T13:05:32.041287Z","iopub.status.idle":"2025-01-18T13:05:32.046037Z","shell.execute_reply.started":"2025-01-18T13:05:32.041262Z","shell.execute_reply":"2025-01-18T13:05:32.045227Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# final data creation step\ntarget = 'efs'\ndf_features = raw_df_train.drop(columns=[target, 'ID', 'efs_time'], axis = 1)\nprint(\"df_features shape : {}\".format(df_features.shape))\n\n\ndf_label  = np.array(raw_df_train[target]).reshape(-1, 1)\nprint(\"Train Label Shape  : {}\".format(df_label.shape))\n\nnumerical_cols, categorical_cols = identify_numerical_catergorical_columns(df_features)\nprint(\"----- Numerical columns -------\")\nprint(numerical_cols)\nprint(\"----- Categorical columns -------\")\nprint(categorical_cols)\npreprocesser_obj = get_data_transformer_object(numerical_cols, categorical_cols)\n\nprocessed_df_arr = preprocesser_obj.fit_transform(df_features)\n\nX_train, X_valid, y_train, y_valid = train_test_split(processed_df_arr, df_label, test_size=0.2, random_state=42)\n\nprint(X_train.shape)\nprint(X_valid.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:37.506720Z","iopub.execute_input":"2025-01-18T13:05:37.507000Z","iopub.status.idle":"2025-01-18T13:05:37.812480Z","shell.execute_reply.started":"2025-01-18T13:05:37.506981Z","shell.execute_reply":"2025-01-18T13:05:37.811724Z"}},"outputs":[{"name":"stdout","text":"df_features shape : (28800, 57)\nTrain Label Shape  : (28800, 1)\n----- Numerical columns -------\n['hla_match_c_high', 'hla_high_res_8', 'hla_low_res_6', 'hla_high_res_6', 'hla_high_res_10', 'hla_match_dqb1_high', 'hla_nmdp_6', 'hla_match_c_low', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'year_hct', 'hla_match_a_high', 'donor_age', 'hla_match_b_low', 'age_at_hct', 'hla_match_a_low', 'hla_match_b_high', 'comorbidity_score', 'karnofsky_score', 'hla_low_res_8', 'hla_match_drb1_high', 'hla_low_res_10']\n----- Categorical columns -------\n['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n(23040, 57)\n(5760, 57)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Baseline for XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n# create model instance\nxgboost_baseline_model = XGBClassifier(\n    n_estimators=100,       # Number of trees\n    learning_rate=0.1,      # Step size shrinkage\n    max_depth=4,            # Maximum tree depth\n    objective='binary:logistic',  # For binary classification\n    eval_metric='logloss',# Evaluation metric\n    enable_categorical=True,\n    random_state=42\n)\n# fit model\nxgboost_baseline_model.fit(X_train, y_train)\n# make predictions\npreds = xgboost_baseline_model.predict(X_valid)\ny_pred_proba = xgboost_baseline_model.predict_proba(X_valid)[:, 1] \naccuracy_score(y_valid, preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:16:24.475546Z","iopub.execute_input":"2025-01-18T13:16:24.475851Z","iopub.status.idle":"2025-01-18T13:16:25.013386Z","shell.execute_reply.started":"2025-01-18T13:16:24.475831Z","shell.execute_reply":"2025-01-18T13:16:25.012670Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.6821180555555556"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"**Here From the XGBoost Classifier the baseline aaccuracy score is 0.6821180555555556**","metadata":{}},{"cell_type":"code","source":"test_df = raw_df_test.drop(columns = ['ID'], axis = 1)\nnumerical_cols_test, categorical_cols_test = identify_numerical_catergorical_columns(df_features)\nprint(numerical_cols)\nprint(categorical_cols_test)\npreprocesser_obj_test = get_data_transformer_object(numerical_cols_test, categorical_cols_test)\nprocessed_test_arr = preprocesser_obj_test.fit_transform(test_df)\nprocessed_test_arr.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T22:01:39.313381Z","iopub.execute_input":"2025-01-16T22:01:39.313795Z","iopub.status.idle":"2025-01-16T22:01:39.342474Z","shell.execute_reply.started":"2025-01-16T22:01:39.313764Z","shell.execute_reply":"2025-01-16T22:01:39.341573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_prob = np.max(xgboost_baseline_model.predict_proba(processed_test_arr), axis = 1)\nprint(submission_prob)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T22:04:16.388864Z","iopub.execute_input":"2025-01-16T22:04:16.389319Z","iopub.status.idle":"2025-01-16T22:04:16.409708Z","shell.execute_reply.started":"2025-01-16T22:04:16.389282Z","shell.execute_reply":"2025-01-16T22:04:16.408608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\nsubmission_df.head()\nsubmission_df[\"prediction\"] = submission_prob\nsubmission_df.to_csv(\"/kaggle/working/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-16T22:04:54.853413Z","iopub.execute_input":"2025-01-16T22:04:54.853763Z","iopub.status.idle":"2025-01-16T22:04:54.864048Z","shell.execute_reply.started":"2025-01-16T22:04:54.853736Z","shell.execute_reply":"2025-01-16T22:04:54.863280Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline for LightGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:05:18.791246Z","iopub.execute_input":"2025-01-18T13:05:18.791566Z","iopub.status.idle":"2025-01-18T13:05:22.730080Z","shell.execute_reply.started":"2025-01-18T13:05:18.791539Z","shell.execute_reply":"2025-01-18T13:05:22.729427Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# create the lighgbm dataset\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalidation_data = lgb.Dataset(X_valid, label=y_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:10:57.303945Z","iopub.execute_input":"2025-01-18T13:10:57.304270Z","iopub.status.idle":"2025-01-18T13:10:57.307910Z","shell.execute_reply.started":"2025-01-18T13:10:57.304242Z","shell.execute_reply":"2025-01-18T13:10:57.307086Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# defining the LightGBM parameters\nparams = {\n    \"objective\": \"binary\",\n    \"metric\": \"binary_logloss\",  # Use \"auc\" for area under the curve metric\n    \"boosting_type\": \"gbdt\",    # Gradient Boosted Decision Trees\n    \"learning_rate\": 0.1,\n    \"num_leaves\": 31,\n    \"max_depth\": -1,\n    \"feature_fraction\": 0.9,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"verbose\": -1\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:10:59.323553Z","iopub.execute_input":"2025-01-18T13:10:59.323845Z","iopub.status.idle":"2025-01-18T13:10:59.327835Z","shell.execute_reply.started":"2025-01-18T13:10:59.323824Z","shell.execute_reply":"2025-01-18T13:10:59.326933Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Train the model\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets = [validation_data],\n    callbacks = [\n        lgb.early_stopping(stopping_rounds = 50)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:12:12.990038Z","iopub.execute_input":"2025-01-18T13:12:12.990315Z","iopub.status.idle":"2025-01-18T13:12:13.662444Z","shell.execute_reply.started":"2025-01-18T13:12:12.990294Z","shell.execute_reply":"2025-01-18T13:12:13.661743Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:357: UserWarning: Converting column-vector to 1d array\n  _log_warning(\"Converting column-vector to 1d array\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[125]\tvalid_0's binary_logloss: 0.588832\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model.best_iteration","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:12:56.229111Z","iopub.execute_input":"2025-01-18T13:12:56.229400Z","iopub.status.idle":"2025-01-18T13:12:56.234073Z","shell.execute_reply.started":"2025-01-18T13:12:56.229377Z","shell.execute_reply":"2025-01-18T13:12:56.233409Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"125"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"y_pred_prob = model.predict(X_valid, num_iteration=model.best_iteration)\ny_pred = (y_pred_prob > 0.5).astype(int)\nprint(y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:13:45.183721Z","iopub.execute_input":"2025-01-18T13:13:45.184056Z","iopub.status.idle":"2025-01-18T13:13:45.207857Z","shell.execute_reply.started":"2025-01-18T13:13:45.184031Z","shell.execute_reply":"2025-01-18T13:13:45.207075Z"}},"outputs":[{"name":"stdout","text":"[1 1 1 ... 0 1 1]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"evaluation_score = accuracy_score(y_valid, y_pred)\nprint(\"Evaluation score is {}\".format(evaluation_score))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T13:16:16.281629Z","iopub.execute_input":"2025-01-18T13:16:16.281952Z","iopub.status.idle":"2025-01-18T13:16:16.288597Z","shell.execute_reply.started":"2025-01-18T13:16:16.281929Z","shell.execute_reply":"2025-01-18T13:16:16.287790Z"}},"outputs":[{"name":"stdout","text":"Evaluation score is 0.6875\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**From the LightGBM classifier the Baseline score is 0.6875**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}